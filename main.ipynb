{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import SimpleDirectoryReader\n",
    "# from llama_index.core.node_parser import TokenTextSplitter\n",
    "# from autorag.data.corpus import llama_text_node_to_parquet\n",
    "\n",
    "# documents = SimpleDirectoryReader('/home/fk/beckData/').load_data()\n",
    "# nodes = TokenTextSplitter().get_nodes_from_documents(documents=documents, chunk_size=512, chunk_overlap=128)\n",
    "# corpus_df = llama_text_node_to_parquet(nodes, '/home/fk/beckData/corpus.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key found!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from a .env file\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set or is incorrect.\")\n",
    "else:\n",
    "    print(\"API Key found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=1.0)\n",
    "\n",
    "corpus_df = pd.read_parquet('path/to/corpus.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autorag.evaluator import Evaluator\n",
    "\n",
    "evaluator = Evaluator(qa_data_path='path/to/qa.parquet', corpus_data_path='path/to/corpus.parquet')\n",
    "evaluator.start_trial('path/to/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/09/24 09:50:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>posthog.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"font-weight: bold\">]</span> &gt;&gt; Anonymized telemetry enabled. See                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">posthog.py:20</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.trychroma.com/telemetry</span> for more information.               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/09/24 09:50:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0mposthog.py:\u001b[1;36m20\u001b[0m\u001b[1m]\u001b[0m >> Anonymized telemetry enabled. See                     \u001b[2mposthog.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m20\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://docs.trychroma.com/telemetry\u001b[0m for more information.               \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/09/24 09:50:10] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1026</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py:1026</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/embeddings</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/09/24 09:50:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m_client.py:\u001b[1;36m1026\u001b[0m\u001b[1m]\u001b[0m >> HTTP Request: \u001b[1;33mPOST\u001b[0m                                \u001b[2m_client.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m1026\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/embeddings\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                 \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/09/24 09:50:12] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span>_client.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1773</span><span style=\"font-weight: bold\">]</span> &gt;&gt; HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py:1773</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span> <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/09/24 09:50:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m_client.py:\u001b[1;36m1773\u001b[0m\u001b[1m]\u001b[0m >> HTTP Request: \u001b[1;33mPOST\u001b[0m                                \u001b[2m_client.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m1773\u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The VGH Munich criticized the comparison made by the AfD politician Florian JÃ¤ger between the Novemberpogrome of 1938 and the COVID-19 vaccination campaign.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autorag.deploy import Runner\n",
    "\n",
    "runner = Runner.from_trial_folder('path/to/trial folder')\n",
    "runner.run('What does the VGH Munich criticized?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autorag.deploy import Runner\n",
    "\n",
    "# runner = Runner.from_trial_folder('path/to/trial folder')\n",
    "# runner.run_api_server(port=8080)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
